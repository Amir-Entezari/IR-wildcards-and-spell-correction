{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# HW1: Developing an Information Retrieval System with Spelling Correction and Wildcard Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## About\n",
    "This project aims to enhance the Information Retrieval (IR) system developed in the first assignment by handling\n",
    "Spelling Correction and Wildcard Queries. This assignment can be completed independently of Project 1. You can\n",
    "find the data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## importing libraries\n",
    "Let's first import libraries we might need. we will use some libraries as typing checking, and some libraries like string just for punctuation.\n",
    "and also, as it is said in Problem file, we can use nltk library for tokenizing. I implement two way for tokenizing, one using nltk and one without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:21.289554Z",
     "end_time": "2024-06-23T19:49:24.588699Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/amir/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/amir/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "from typing import List\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Main classes\n",
    "Now let's define our classes. I define two main classes and two small for this project. Trie and Information Retrieval System are the two main classes and token and node are two small class that I use them in main classes respectively.\n",
    "### Algorithm\n",
    "Befor going to implementation, let's summarize our algorithm and approach:\n",
    "First of all, we get a list of documents in format of string; we need to tokenize all these documents. we can split all words using whitespace. Then, we need to get rid of punctuation. This will be done using nltk. at last, it's better to lower case all words so we can index for example \"another\" and \"Another\" in same. After tokenizing, we have to create our posting_list, which is the core of this project. To do this, we should loop over all documents, then inside this loop, we loop over all the tokens that are in the current document. then we check if the length of posting_list is zero, then we add this token as first word. else if the length of posting_list is more than 0, we find the correct index of the token in posting_list alphabetically. then we check if this token, has been already in posting_list, we just add the current document index in tokens.docs, else, we add this token in the posting_list, then add the current document index. Also we store index of occurence of the token in the relevant documents.\n",
    "After creating the posting list, we should add all words and their permutations to a Trie tree; We need to do this to handle wildcard queries.\n",
    "this can be done by insert all words of the posting_list, to the trie. The algorithm is completely describe in docstring of the Trie class.\n",
    "Now we create our posting list, we can easily search a query. To do this, I have a main search function that do one things at first, it check if each side of the query, contains wildcard or not. if yes, it replace that side by the list of a word that matches the wildcard query, and if it does not contain wildcard, it just replace that word by a list that contain just the same word; we do it according to the fact that in each case of (AND, OR, NOT, Near) we should union the list of each side of the main operation, and then do the main operation.\n",
    "Now let's see what do we do in wildcard query; for each single token that contain *, If there is just one *, it will add a '$' at the end of the word, and then permutate it such that the * pose on the end of the string, and then search it in prefix_trie and will return the all match tokens. If there are two *, it convert two * and the characters between these two into one *. Then do the same thing for having one *. And from resulted matched, it search if they have the sequence characters of between two * in the input token.\n",
    "Now we can do the boolean or aproxy queries. Before explain each, there is a note: in each operation, for each word we try to find it from the posting list, and if can't, we do the spell correction. Now let's define boolean and aproxy operations:\n",
    "For just getting the documents of a one word, we have the function get_word_docs; this simple function gets a token and will return all index of documents that this token is appeared in. For intersecting(AND) 2 words, we just need to return document's index of our 2 words that are occurred in same documents. for union(OR), we gather index of word1 with word2. for NOT, we just need to return all document's index that are not in the list of documents that contain our word. And at last, for near, we just need to find documents that either each of these word has been occurred near by at most k words on left or right. we have to cases:\n",
    " * 1)the first_word occurred before second_word.\n",
    " * 2)second_word occurred before first_word.\n",
    "so we loop over a tuple (p1, p2) to cover ordered occurrence of each word. then for each word we loop over its documents, and in each document, we loop over index of that the token is occurred. then if other word(let's say second) is in documents[word1_idx:word1_idx+length], we add the current document index.\n",
    "\n",
    "### challenges\n",
    "I had two challelnges for this project:\n",
    "* 1)create the prefix tree and retrieve wildcard query. Soulution: add all circular permutation of words to the tree\n",
    "* 2)spell checking of a word. Solution: compare all edit distance of a word with all posting list words\n",
    "we will explain the algorithms in function too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Utility functions\n",
    "Let's define a function to get all circular permutation of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.571295Z",
     "end_time": "2024-06-23T19:49:24.588853Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_all_permutations(input_str: str):\n",
    "    \"\"\"\n",
    "    this function will generate all circular permutation of a string\n",
    "    \"\"\"\n",
    "    perm_list = []\n",
    "    n = len(input_str)\n",
    "    for i in range(n):\n",
    "        permuterm = input_str[i:n] + input_str[0:i]\n",
    "        perm_list.append(permuterm)\n",
    "    return perm_list\n",
    "\n",
    "def edit_distance(word1: str, word2: str):\n",
    "    \"\"\"\n",
    "    this function will calculate the distance of between two word. The distance means the total number of operation\n",
    "    that we need to convert each word to other\n",
    "    :param word1: str\n",
    "        first word you want to calculate distance of with another\n",
    "    :param word2:\n",
    "        second word you want to calculate distance of with another\n",
    "    :return:\n",
    "        the edit distance of between word1 and word2\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(word2))] for i in range(len(word1))]\n",
    "    for i in range(1, len(word1)):\n",
    "        dp[i][0] = i\n",
    "    for j in range(1, len(word2)):\n",
    "        dp[0][j] = j\n",
    "    for i in range(1, len(word1)):\n",
    "        for j in range(1, len(word2)):\n",
    "            dp[i][j] = min(dp[i - 1][j - 1] + (0 if word1[i] == word2[j] else 1),\n",
    "                           dp[i - 1][j] + 1,\n",
    "                           dp[i][j - 1] + 1)\n",
    "    return dp[-1][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Let's define our preprocess functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize NLTK stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def read_documents(doc_folder):\n",
    "    \"\"\"\n",
    "    Reads all text files in the specified directory and returns a dictionary\n",
    "    with document ids as keys and the content as values.\n",
    "    \"\"\"\n",
    "    documents = {}\n",
    "    for doc_file in os.listdir(doc_folder):\n",
    "        if doc_file.endswith('.txt'):\n",
    "            doc_path = os.path.join(doc_folder, doc_file)\n",
    "            with open(doc_path, 'r', encoding='utf-8') as file:\n",
    "                documents[doc_file] = file.read()\n",
    "    return documents\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the text by tokenizing, converting to lowercase, removing punctuation,\n",
    "    and filtering out stop words.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Filter out stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "def preprocess_documents(documents):\n",
    "    \"\"\"\n",
    "    Apply text preprocessing to each document in the dictionary.\n",
    "    \"\"\"\n",
    "    preprocessed_docs = []\n",
    "    for doc_id, content in enumerate(documents):\n",
    "        preprocessed_docs.append(preprocess_text(content))\n",
    "    return preprocessed_docs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.571354Z",
     "end_time": "2024-06-23T19:49:24.588924Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indexing\n",
    "Now let's define our main class:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from typing import List\n",
    "\n",
    "from src.utils import edit_distance\n",
    "\n",
    "\n",
    "class Token:\n",
    "    def __init__(self, word: str):\n",
    "        self.word = word\n",
    "        self.docs = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.word\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.word\n",
    "\n",
    "\n",
    "class InvertedIndex:\n",
    "    \"\"\"\n",
    "    In this class, I implement an information retrieval system which can search a query among documents.\n",
    "    ...\n",
    "    Attributes:\n",
    "    -----------\n",
    "    documents: List\n",
    "        list of documents in format of string.\n",
    "    posting_list: List[Token]\n",
    "        list of Token objects. Tokens store a string and document's indexes\n",
    "    stop_word: set\n",
    "        set of stop words to check when tokenizing\n",
    "    case_sensitive: bool\n",
    "        a boolean to determine whether we want to distinguish between lowercase and uppercase form.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    Methods defined here:\n",
    "        __init__(self, documents: List, case_sensitive=False):\n",
    "            Constructor will set initial attributes like documents and case_sensitive. NOTE that documents should be\n",
    "            list of strings at first.\n",
    "            :parameter\n",
    "            ---------\n",
    "            documents:List\n",
    "                list of strings at first. but then chagnes to list of lists of strings\n",
    "            :return\n",
    "                None\n",
    "        add_document(self, doc_idx, doc):\n",
    "            this function will add a document to the posting list. it will loop over all tokens in the document and\n",
    "            add them to the posting list.\n",
    "            :param doc_idx:\n",
    "                index of the document in the documents list\n",
    "            :param doc:\n",
    "                list of tokens in the document\n",
    "            :return:\n",
    "                None\n",
    "        create_posting_list(self):\n",
    "            calling this function, will create posting list of all occurred words cross all documents.\n",
    "            :parameter\n",
    "                None\n",
    "            :return\n",
    "                None\n",
    "        get_token_index(self, x):\n",
    "            this function find index of a word in posting list using binary search algorithm.\n",
    "            :parameter\n",
    "                x:str\n",
    "                    the word you want to find its index\n",
    "            :return\n",
    "                int: index of the word in posting_list\n",
    "        get_token(self, token):\n",
    "                This function will return the token object that contains docs informations. if the given token is not in the\n",
    "                posting_list, it return the spell corrected token.\n",
    "                :param token:\n",
    "                    token you want to fetch it from posting list\n",
    "                :return:\n",
    "                    return the instance of token from posting list\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, documents: List, case_sensitive=False):\n",
    "        \"\"\"\n",
    "        Constructor will set initial attributes like documents and case_sensitive. NOTE that documents should be\n",
    "            list of strings at first.\n",
    "            :parameter\n",
    "            ---------\n",
    "            documents:List\n",
    "                list of strings at first. but then chagnes to list of lists of strings\n",
    "            :return\n",
    "                None\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.posting_list: List[Token] = []\n",
    "        self.stop_words: set = set(nltk.corpus.stopwords.words('english') + list(string.punctuation))\n",
    "        self.case_sensitive = case_sensitive\n",
    "\n",
    "    def add_document(self, doc_idx, doc):\n",
    "        for token_idx, token in enumerate(doc):\n",
    "            if len(self.posting_list) == 0:\n",
    "                self.posting_list.append(Token(token))\n",
    "                self.posting_list[0].docs.append({'doc_idx': doc_idx, 'indexes': [token_idx]})\n",
    "                continue\n",
    "            i = 0\n",
    "            while i < len(self.posting_list) and token > self.posting_list[i].word:\n",
    "                i += 1\n",
    "            if i == len(self.posting_list):\n",
    "                self.posting_list.append(Token(token))\n",
    "                # self.posting_list[i].post_idx.append(post_idx)\n",
    "            elif token != self.posting_list[i].word:\n",
    "                self.posting_list.insert(i, Token(token))\n",
    "\n",
    "            if doc_idx not in [elem['doc_idx'] for elem in self.posting_list[i].docs]:\n",
    "                self.posting_list[i].docs.append({'doc_idx': doc_idx, 'indexes': [token_idx]})\n",
    "            else:\n",
    "                self.posting_list[i].docs[-1]['indexes'].append(token_idx)\n",
    "\n",
    "    def create_posting_list(self):\n",
    "        \"\"\"\n",
    "        calling this function, will create posting list of all occurred words cross all documents. in this function, we\n",
    "        loop over all documents, then inside this loop, we loop over all the tokens that are in the current document.\n",
    "        the we check if the length of posting_list is zero, then we add this token as first word. else if the length of\n",
    "        posting_list is more than 0, we find the correct index of the token in posting_list alphabetically. then we check\n",
    "        if this token, has been already in posting_list, we just add the current document index in tokens.docs, else, we\n",
    "        add this token in the posting_list, then add the current document index.\n",
    "            :parameter\n",
    "                None\n",
    "            :return\n",
    "                None\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for doc_idx, doc in enumerate(self.documents):\n",
    "            self.add_document(doc_idx=doc_idx, doc=doc)\n",
    "\n",
    "    def spell_correction(self, word):\n",
    "        \"\"\"\n",
    "        this function will return the nearest word from posting_list to a given word which is might be incorrect.\n",
    "        :param word:\n",
    "            the word you want to return correction of it from posting list\n",
    "        :return:\n",
    "            index of the nearest token from posting list to the given word\n",
    "        \"\"\"\n",
    "        nearest_idx = 0\n",
    "        nearest_val = edit_distance(self.posting_list[nearest_idx].word, word)\n",
    "        for idx in range(len(self.posting_list)):\n",
    "            temp_dist = edit_distance(self.posting_list[idx].word, word)\n",
    "            if temp_dist < nearest_val:\n",
    "                nearest_idx = idx\n",
    "                nearest_val = temp_dist\n",
    "        return nearest_idx\n",
    "\n",
    "    def get_token_index(self, x):\n",
    "        \"\"\"\n",
    "        this function find index of a word in posting list using binary search algorithm.\n",
    "            :parameter\n",
    "                x:str\n",
    "                    the word you want to find its index\n",
    "            :return\n",
    "                int: index of the word in posting_list\n",
    "        \"\"\"\n",
    "        low = 0\n",
    "        high = len(self.posting_list) - 1\n",
    "        mid = 0\n",
    "        while low <= high:\n",
    "            mid = (high + low) // 2\n",
    "            if self.posting_list[mid].word < x:\n",
    "                low = mid + 1\n",
    "            elif self.posting_list[mid].word > x:\n",
    "                high = mid - 1\n",
    "            else:\n",
    "                return mid\n",
    "        return -1\n",
    "\n",
    "    def get_token(self, token):\n",
    "        \"\"\"\n",
    "        This function will return the token object that contains docs informations. if the given token is not in the\n",
    "        posting_list, it return the spell corrected token.\n",
    "        :param token:\n",
    "            token you want to fetch it from posting list\n",
    "        :return:\n",
    "            return the instance of token from posting list\n",
    "        \"\"\"\n",
    "        p = self.get_token_index(token)\n",
    "        if p == -1:\n",
    "            p = self.spell_correction(token)\n",
    "        return self.posting_list[p]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.571404Z",
     "end_time": "2024-06-23T19:49:24.588980Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Trie (prefixtree)\n",
    "Let's define our prefix tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.571543Z",
     "end_time": "2024-06-23T19:49:24.589034Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    \"\"\"\n",
    "    This class is the main class of nodes that are used in Trie class\n",
    "    ...\n",
    "    Attributes:\n",
    "    ----------\n",
    "    char: str\n",
    "        character that is in node\n",
    "    is_end: bool\n",
    "        this attribute determines if the current node is the end of a word or not.\n",
    "    children: dict\n",
    "        this attribute contains the children nodes of a node.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    Methods defined here:\n",
    "        __init__(self, char):\n",
    "            Constructor will set initial attribute, char.\n",
    "            :parameter\n",
    "            ---------\n",
    "            char:str\n",
    "                the character which is in current node.\n",
    "            :return\n",
    "                None\n",
    "        __repr__(self):\n",
    "            represents the instance of node as the char attribute.\n",
    "        __str__(self):\n",
    "            print the instance of node as the char attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char):\n",
    "        self.char = char\n",
    "        self.is_end = False\n",
    "        self.children = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.char\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.char\n",
    "\n",
    "\n",
    "class Trie(object):\n",
    "    \"\"\"\n",
    "    This class is the prefix tree, Or Trie. This tree contains nodes that each is a character and have children as the\n",
    "    next character. In this tree, words are the nodes that their is_end attributes are True.\n",
    "    ...\n",
    "    Attributes:\n",
    "    ----------\n",
    "    root: TrieNode\n",
    "        Root of the whole tree.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    Methods defined here:\n",
    "        __init__(self):\n",
    "            Constructor will create the root by TrieNode object.\n",
    "            :parameter\n",
    "                None\n",
    "            :return\n",
    "                None\n",
    "        insert(self, word):\n",
    "            This function insert a word into the tree. It first sets the current node to root of the tree,\n",
    "            then loop over the characters of the word, and if the current char exists in children of the current node,\n",
    "            sets the current node to that child, and else, it create a new_node by the current char and add it to the\n",
    "            children of the current node. And after the loop, the is_end attribute of the last node will set to True.\n",
    "            :parameter\n",
    "                - word:str\n",
    "                    the word you want to insert into the tree.\n",
    "            :return\n",
    "                The last node which is the end of the word.\n",
    "        _dfs(self, node, prefix, result=[]):\n",
    "            This function get a node(root of a tree or subtree) and a prefix, then return all words that contain the\n",
    "            given prefix in the result argument.\n",
    "\n",
    "            :parameter\n",
    "                - node:TrieNode\n",
    "                    the node to start with\n",
    "                - prefix:str\n",
    "                    the current prefix, for tracing a\n",
    "                    word while traversing the trie\n",
    "                - result:list\n",
    "                    the list that the function will add all words into it.\n",
    "            :return\n",
    "                return all words that contain the given prefix in the given tree.\n",
    "\n",
    "        dfs_helper(self, node, prefix):\n",
    "            this function is a helper function for _dfs, because the _dfs function store results in its parameter.\n",
    "            :parameter\n",
    "                - node:TrieNode\n",
    "                    the node to start with\n",
    "                - prefix:str\n",
    "                    the current prefix, for tracing a\n",
    "                    word while traversing the trie\n",
    "            :return\n",
    "                return all words that contain the given prefix in the given tree.\n",
    "\n",
    "        print_all_words(self):\n",
    "            this function will print all words of a Trie.\n",
    "            :parameter\n",
    "                None\n",
    "            :return\n",
    "                None\n",
    "        query(self, x:str):\n",
    "            This function is as same as the dfs_helper function, but first check if the given word is in trie or not, then\n",
    "            call the the dfs_helper with the root node and return all words contain x as prefix(include x if there exist).\n",
    "            :parameter\n",
    "                - x:str\n",
    "                    the given word or prefix\n",
    "            :return\n",
    "                return all words contain x as prefix(include x if there exist).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The trie has at least the root node.\n",
    "        The root node does not store any character\n",
    "        \"\"\"\n",
    "        self.root = TrieNode(\"\")\n",
    "\n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        This function insert a word into the tree. It first sets the current node to root of the tree,\n",
    "        then loop over the characters of the word, and if the current char exists in children of the current node,\n",
    "        sets the current node to that child, and else, it create a new_node by the current char and add it to the\n",
    "        children of the current node. And after the loop, the is_end attribute of the last node will set to True.\n",
    "            :parameter\n",
    "                - word:str\n",
    "                    the word you want to insert into the tree.\n",
    "            :return\n",
    "                The last node which is the end of the word.\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                new_node = TrieNode(char)\n",
    "                node.children[char] = new_node\n",
    "                node = new_node\n",
    "        node.is_end = True\n",
    "        return node\n",
    "\n",
    "    def _dfs(self, node, prefix, result=[]):\n",
    "        \"\"\"\n",
    "        This function get a node(root of a tree or subtree) and a prefix, then return all words that contain the\n",
    "        given prefix in the result argument.\n",
    "            :parameter\n",
    "                - node:TrieNode\n",
    "                    the node to start with\n",
    "                - prefix:str\n",
    "                    the current prefix, for tracing a\n",
    "                    word while traversing the trie\n",
    "                - result:list\n",
    "                    the list that the function will add all words into it.\n",
    "            :return\n",
    "                 return all words that contain the given prefix in the given tree.\n",
    "        \"\"\"\n",
    "        if node.is_end:\n",
    "            # result.append(node)\n",
    "            result.append(prefix + node.char)\n",
    "\n",
    "        for child in node.children.values():\n",
    "            self._dfs(child, prefix + node.char, result)\n",
    "\n",
    "    def dfs_helper(self, node, prefix):\n",
    "        \"\"\"\n",
    "        this function is a helper function for _dfs, because the _dfs function store results in its parameter.\n",
    "            :parameter\n",
    "                - node:TrieNode\n",
    "                    the node to start with\n",
    "                - prefix:str\n",
    "                    the current prefix, for tracing a\n",
    "                    word while traversing the trie\n",
    "            :return\n",
    "                return all words that contain the given prefix in the given tree.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        self._dfs(node, prefix, result=result)\n",
    "        return result\n",
    "\n",
    "    def print_all_words(self):\n",
    "        \"\"\"\n",
    "        print_all_words(self):\n",
    "            this function will print all words of a Trie.\n",
    "            :parameter\n",
    "                None\n",
    "            :return\n",
    "                None\n",
    "        \"\"\"\n",
    "        for word in sorted(self.dfs_helper(self.root, '')):\n",
    "            print(word)\n",
    "\n",
    "    def query(self, x: str):\n",
    "        \"\"\"\n",
    "        This function is as same as the dfs_helper function, but first check if the given word is in trie or not, then\n",
    "        call the the dfs_helper with the root node and return all words contain x as prefix(include x if there exist).\n",
    "        :parameter\n",
    "            - x:str\n",
    "                the given word or prefix\n",
    "        :return\n",
    "            return all words contain x as prefix(include x if there exist).\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        for char in x:\n",
    "            if char in node.children:\n",
    "                node = node.children[char]\n",
    "            else:\n",
    "                return []\n",
    "        result = self.dfs_helper(node, x[:-1])\n",
    "        return sorted(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## querying\n",
    "At last we complete our IR system by implementing a QueryProcessor class. This class will use the InvertedIndex class we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.580809Z",
     "end_time": "2024-06-23T19:49:24.589638Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class QueryProcessor:\n",
    "    \"\"\"\n",
    "    In this class, I implement an information retrieval system which can search a query among documents.\n",
    "    ...\n",
    "    Attributes:\n",
    "    -----------\n",
    "    indexing_model: InvertedIndex\n",
    "        an instance of InvertedIndex class which has been created by indexing documents.\n",
    "    Methods\n",
    "    -------\n",
    "    Methods defined here:\n",
    "        get_word_docs(self, word: str):\n",
    "                this simple function gets a token and will return all index of documents that this token is appeared in.\n",
    "                :param word:\n",
    "                    a word that you want to search.\n",
    "                :return:\n",
    "                    list of indexes of documents.\n",
    "        intersect(self, first_word, second_word):\n",
    "                this function get two words, and find documents that both of these word has been occurred.\n",
    "                :parameter\n",
    "                first_word: str\n",
    "                    first word you want to search\n",
    "                second_word: str\n",
    "                    second word you want to search\n",
    "                :return\n",
    "                    list of indexes of documents.\n",
    "            union(self, first_word, second_word):\n",
    "                this function get two words, and find documents that either each of these word has been occurred.\n",
    "                :parameter\n",
    "                first_word: str\n",
    "                    first word you want to search\n",
    "                second_word: str\n",
    "                    second word you want to search\n",
    "                :return\n",
    "                    list of indexes of documents.\n",
    "            not_in(self, word):\n",
    "                this function get one word, and find documents that this word has been not occurred.\n",
    "                :parameter\n",
    "                word: str\n",
    "                    the word you want to search\n",
    "                :return\n",
    "                    list of indexes of documents.\n",
    "            near(self, first_word, second_word, length):\n",
    "                this function get two words, and find documents that either each of these word has been occurred near by at most 3 words on left or right.\n",
    "                :parameter\n",
    "                first_word: str\n",
    "                    first word you want to search\n",
    "                second_word: str\n",
    "                    second word you want to search\n",
    "                :return\n",
    "                    list of indexes of documents.\n",
    "            search(self, query):\n",
    "                this function get a query and recognize what kind of query is; then search the query.\n",
    "                :parameter\n",
    "                    query: str\n",
    "                        the query that user wants to search\n",
    "                :return\n",
    "                    print list of indexes of documents in a pretty way.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indexing_model):\n",
    "        self.indexing_model = indexing_model\n",
    "        self.prefix_trie: Trie = Trie()\n",
    "\n",
    "    def get_word_docs(self, word):\n",
    "        t = self.indexing_model.get_token(word)\n",
    "        result = set()\n",
    "        for doc in t.docs:\n",
    "            result.add(doc['doc_idx'])\n",
    "        return result\n",
    "\n",
    "    def create_prefix_trie(self):\n",
    "        \"\"\"\n",
    "        This functions should run after create_posting_list to add all words to prefix_trie to create it.\n",
    "        :return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if self.indexing_model.posting_list:\n",
    "            for token in self.indexing_model.posting_list:\n",
    "                # Add permuterms\n",
    "                permuterms = get_all_permutations(token.word + '$')\n",
    "                for term in permuterms:\n",
    "                    node = self.prefix_trie.insert(term)\n",
    "        else:\n",
    "            raise Exception(\"You should first create posting list\")\n",
    "\n",
    "    def wildcard_query(self, token: str):\n",
    "        \"\"\"\n",
    "        This function gets a token that contain * and return matched word.\n",
    "        If there is just one *, it will add a '$' at the end of the word, and then permutate it such that the * pose on\n",
    "        the end of the string, and then search it in prefix_trie and will return the all match tokens.\n",
    "        If there are two *, it convert two * and the characters between these two into one *. Then do the same thing for\n",
    "        having one *. And from resulted matched, it search if they have the sequence characters of between two * in the\n",
    "        input token.\n",
    "        :param token:\n",
    "            the token that has * and you wants to get all matches.\n",
    "        :return:\n",
    "            return all matches\n",
    "        \"\"\"\n",
    "        if token.count('*') == 1:\n",
    "            star_idx = token.index('*')\n",
    "            result_tokens = self.prefix_trie.query(token[star_idx + 1:] + token[0:star_idx])\n",
    "            for i, word in enumerate(result_tokens):\n",
    "                dollar_idx = word.index('$')\n",
    "                result_tokens[i] = word[dollar_idx + 1:] + word[0:dollar_idx]\n",
    "            return result_tokens\n",
    "\n",
    "        elif token.count('*') == 2:\n",
    "            star1_idx = token.index('*')\n",
    "            star2_idx = token.index('*', star1_idx + 1)\n",
    "            result_tokens = self.prefix_trie.query(token[star2_idx + 1:] + token[0:star1_idx])\n",
    "            for i, word in enumerate(result_tokens):\n",
    "                dollar_idx = word.index('$')\n",
    "                result_tokens[i] = word[dollar_idx + 1:] + word[0:dollar_idx]\n",
    "            # print(result_tokens)\n",
    "            result = []\n",
    "            for word in result_tokens:\n",
    "                if token[star1_idx + 1:star2_idx] in word:\n",
    "                    result.append(word)\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Query is not valid\")\n",
    "\n",
    "    def intersect(self, first_word, second_word):\n",
    "        docs1 = self.get_word_docs(first_word)\n",
    "        docs2 = self.get_word_docs(second_word)\n",
    "        return set(docs1 & docs2)\n",
    "\n",
    "    def union(self, first_word, second_word):\n",
    "        docs1 = self.get_word_docs(first_word)\n",
    "        docs2 = self.get_word_docs(second_word)\n",
    "        return set(docs1 | docs2)\n",
    "\n",
    "    def not_in(self, word):\n",
    "        all_docs = set(range(len(self.indexing_model.documents)))\n",
    "        word_docs = self.get_word_docs(word)\n",
    "        return set(all_docs - word_docs)\n",
    "\n",
    "    def near(self, first_word, second_word, distance):\n",
    "        result = set()\n",
    "        t1 = self.indexing_model.get_token(first_word)\n",
    "        t2 = self.indexing_model.get_token(second_word)\n",
    "        for t in (t1, t2):\n",
    "            for doc in t.docs:\n",
    "                for idx in doc['indexes']:\n",
    "                    if second_word in self.indexing_model.documents[doc[\"doc_idx\"]][idx + 1:idx + 1 + distance]:\n",
    "                        result.add(doc['doc_idx'])\n",
    "        return set(result)\n",
    "\n",
    "    def search(self, query):\n",
    "        query_parts = query.lower().split()\n",
    "        if len(query_parts) > 2:\n",
    "            if '*' not in query_parts[0]:\n",
    "                query_parts[0] = [query_parts[0]]\n",
    "            if '*' not in query_parts[2]:\n",
    "                query_parts[2] = [query_parts[2]]\n",
    "            if '*' in query_parts[0]:\n",
    "                query_parts[0] = self.wildcard_query(query_parts[0] + '$')\n",
    "            if '*' in query_parts[2]:\n",
    "                query_parts[2] = self.wildcard_query(query_parts[1] + '$')\n",
    "        if len(query_parts) == 1:\n",
    "            if '*' in query_parts[0]:\n",
    "                query_parts[0] = self.wildcard_query(query_parts[0] + '$')\n",
    "            else:\n",
    "                query_parts[0] = [query_parts[0]]\n",
    "            result = self.get_word_docs(query_parts[0][0])\n",
    "            for token1 in query_parts[0]:\n",
    "                result = result.union(self.get_word_docs(token1))\n",
    "            return result\n",
    "        elif 'and' in query_parts:\n",
    "            result = set()\n",
    "            for token1 in query_parts[0]:\n",
    "                for token2 in query_parts[2]:\n",
    "                    result = result.union(self.intersect(token1, token2))\n",
    "            return result\n",
    "        elif 'or' in query_parts:\n",
    "            result = set()\n",
    "            for token1 in query_parts[0]:\n",
    "                for token2 in query_parts[2]:\n",
    "                    result = result.union(self.union(token1, token2))\n",
    "            return result\n",
    "        elif 'not' in query_parts:\n",
    "            if '*' in query_parts[0]:\n",
    "                query_parts[1] = self.wildcard_query(query_parts[1] + '$')\n",
    "            else:\n",
    "                query_parts[1] = [query_parts[1]]\n",
    "            result = self.not_in(query_parts[1][0])\n",
    "            for token1 in query_parts[1]:\n",
    "                result = result.intersection(self.not_in(token1))\n",
    "            return result\n",
    "        elif 'near' in query:\n",
    "            distance = int(query_parts[1].split('/')[1])\n",
    "            result = set()\n",
    "            for token1 in query_parts[0]:\n",
    "                for token2 in query_parts[2]:\n",
    "                    result = result.union(self.near(token1, token2, distance=distance))\n",
    "            return self.near(query_parts[0], query_parts[2], distance)\n",
    "        else:\n",
    "            return list(self.get_word_docs(query_parts[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Test\n",
    "Now let's test our system using samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### read documents\n",
    "First let's define a documetns_test list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.583319Z",
     "end_time": "2024-06-23T19:49:24.589729Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample documents:\n",
    "documents = [\n",
    "    'This is a simple example document. It contains several words. The words should be processed and indexed.',\n",
    "    'Another example document with different content. Document indexing is important for retrieval.',\n",
    "    'Another example document to test Boolean search capabilities. This document contains relevant content.',\n",
    "    'Automat Automata Automation Automatic nobody nood need nid nobody nearby nekoray neyshabour nooobbbbboooy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Build our system\n",
    "\n",
    "# Create an object of our system\n",
    "ir_system = InformationRetrievalSystem(documents_test)\n",
    "# Tokenize documents\n",
    "ir_system.tokenize(use_nltk=True)\n",
    "# Create posting_list\n",
    "ir_system.create_posting_list()\n",
    "# Create the prefix_trie\n",
    "ir_system.create_prefix_trie()Now let's build our system and call initial functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.586437Z",
     "end_time": "2024-06-23T19:49:24.597370Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess documents\n",
    "preprocessed_documents = preprocess_documents(documents)\n",
    "\n",
    "# Initialize the Information Retrieval System with the preprocessed documents\n",
    "inverted_index = InvertedIndex(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[another,\n automat,\n automata,\n automatic,\n automation,\n boolean,\n capabilities,\n contains,\n content,\n different,\n document,\n example,\n important,\n indexed,\n indexing,\n nearby,\n need,\n nekoray,\n neyshabour,\n nid,\n nobody,\n nood,\n nooobbbbboooy,\n processed,\n relevant,\n retrieval,\n search,\n several,\n simple,\n test,\n words]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create posting lists\n",
    "inverted_index.create_posting_list()\n",
    "\n",
    "# Let's see the posting list\n",
    "inverted_index.posting_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.595821Z",
     "end_time": "2024-06-23T19:49:24.663999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639354Z",
     "end_time": "2024-06-23T19:49:24.664296Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** ir_system documents:\n",
      " [['simple', 'example', 'document', 'contains', 'several', 'words', 'words', 'processed', 'indexed'], ['another', 'example', 'document', 'different', 'content', 'document', 'indexing', 'important', 'retrieval'], ['another', 'example', 'document', 'test', 'boolean', 'search', 'capabilities', 'document', 'contains', 'relevant', 'content'], ['automat', 'automata', 'automation', 'automatic', 'nobody', 'nood', 'need', 'nid', 'nobody', 'nearby', 'nekoray', 'neyshabour', 'nooobbbbboooy']]\n"
     ]
    }
   ],
   "source": [
    "print('**** ir_system documents:\\n', inverted_index.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639425Z",
     "end_time": "2024-06-23T19:49:24.664424Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** ir_system posting list:\n",
      " [another, automat, automata, automatic, automation, boolean, capabilities, contains, content, different, document, example, important, indexed, indexing, nearby, need, nekoray, neyshabour, nid, nobody, nood, nooobbbbboooy, processed, relevant, retrieval, search, several, simple, test, words]\n"
     ]
    }
   ],
   "source": [
    "print('**** ir_system posting list:\\n', inverted_index.posting_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Testing\n",
    "Now we can test and query to our system. Note that the documents are 0-based indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "ir_system = QueryProcessor(inverted_index)\n",
    "ir_system.create_prefix_trie()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639508Z",
     "end_time": "2024-06-23T19:49:24.664483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639554Z",
     "end_time": "2024-06-23T19:49:24.664589Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2}\n",
      "{3}\n",
      "{0, 1, 2}\n",
      "{3}\n",
      "{0, 1, 2}\n",
      "{1, 2}\n",
      "{3}\n",
      "{3}\n"
     ]
    }
   ],
   "source": [
    "# Execute a standard Boolean query\n",
    "print(ir_system.search('example and content'))\n",
    "\n",
    "# Execute a proximity query\n",
    "print(ir_system.search('not example'))\n",
    "\n",
    "# Execute an OR query\n",
    "print(ir_system.search('example or content'))\n",
    "\n",
    "# Execute a NOT query\n",
    "print(ir_system.search('not example'))\n",
    "\n",
    "# Execute wildcard queries and spell correction\n",
    "print(ir_system.search('not t*'))\n",
    "print(ir_system.search('exa*le and contrnt'))\n",
    "print(ir_system.search('n*d and Automation'))\n",
    "print(ir_system.search('n*b*y and Automation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Let's test it on our dataset file too. NOTE that the documents should be provided in the same directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639687Z",
     "end_time": "2024-06-23T19:49:24.664710Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy and Unhappy Renters.txt\n",
      "A Festival of Books.txt\n",
      "A Murder-Suicide.txt\n",
      "Jerry Decided To Buy a Gun.txt\n",
      "Better To Be Unlucky.txt\n",
      "Pulling Out Nine Tons of Trash.txt\n",
      "Food Fight Erupted in Prison.txt\n",
      "Crazy Housing Prices.txt\n",
      "Trees Are a Threat.txt\n",
      "Man Injured at Fast Food Place.txt\n",
      "Freeway Chase Ends at Newsstand.txt\n",
      "Cloning Pets.txt\n",
      "Sara Went Shopping.txt\n",
      "Gasoline Prices Hit Record High.txt\n",
      "Rentals at the Oceanside Community.txt\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../dataset/raw'\n",
    "documents_test = []\n",
    "for filename in os.listdir(dataset_path):\n",
    "    filepath = os.path.join(dataset_path, filename)\n",
    "    if filepath.endswith('.txt'):\n",
    "        print(filename)\n",
    "        # Use encoding cp1252 for test cases if an error raised\n",
    "        documents_test.append(open(filepath, encoding='cp1252').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Build our system\n",
    "Now let's build our system and call initial functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.639753Z",
     "end_time": "2024-06-23T19:49:24.664765Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess documents\n",
    "preprocessed_documents = preprocess_documents(documents_test)\n",
    "\n",
    "# Initialize the Information Retrieval System with the preprocessed documents\n",
    "inverted_index = InvertedIndex(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 10,\n 1000,\n 1000x,\n 100x,\n 10x,\n 11,\n 110000,\n 12,\n 120,\n 120000,\n 15,\n 150,\n 15percent,\n 1992,\n 1993,\n 1995,\n 1x,\n 20,\n 200,\n 2000,\n 20000,\n 209,\n 214,\n 222,\n 230000,\n 24yearold,\n 25,\n 25000,\n 25000we,\n 280,\n 2995,\n 3,\n 30,\n 300,\n 3037,\n 350,\n 38,\n 3995,\n 4000,\n 4000residents,\n 5,\n 50,\n 500,\n 50000,\n 500x,\n 50th,\n 50x,\n 510000it,\n 60,\n 6000,\n 65yearold,\n 7,\n 70000,\n 70yearold,\n 74yearold,\n 75,\n 75000,\n 76,\n 79yearold,\n 87,\n 9,\n 90,\n 900,\n 9000,\n 99,\n able,\n abuse,\n accidentally,\n according,\n acres,\n actually,\n administration,\n afghan,\n agency,\n ago,\n aid,\n alan,\n allen,\n allotments,\n allow,\n allowing,\n almost,\n alone,\n along,\n already,\n also,\n altadena,\n although,\n always,\n ambulance,\n american,\n ammunition,\n among,\n amount,\n amounts,\n amputated,\n angelenos,\n angeles,\n anniversary,\n annual,\n another,\n antennas,\n anyone,\n anything,\n apartment,\n apartments,\n apparent,\n appears,\n appliances,\n apply,\n approved,\n april,\n arcadia,\n area,\n arizona,\n around,\n arrived,\n asked,\n asking,\n assisted,\n attendance,\n attitudes,\n attract,\n audience,\n authors,\n auto,\n autograph,\n availablethis,\n avenue,\n average,\n avoid,\n avoided,\n away,\n awaybarget,\n baby,\n back,\n backbreaking,\n bad,\n bag,\n bags,\n baldwin,\n balls,\n ban,\n bancity,\n band,\n bang,\n barco,\n barget,\n barneys,\n bartering,\n basic,\n basis,\n batteries,\n bay,\n beach,\n become,\n behind,\n believes,\n beloved,\n berserk,\n best,\n better,\n bicycles,\n big,\n bigger,\n bikers,\n bill,\n binocularsdifferent,\n biopsy,\n birder,\n birding,\n births,\n bizarre,\n black,\n blanket,\n blind,\n block,\n blocks,\n blue,\n bob,\n book,\n books,\n bookstore,\n boon,\n boots,\n born,\n bottle,\n bottles,\n bought,\n bowling,\n boxes,\n boy,\n braked,\n brakes,\n brand,\n breakfast,\n bring,\n brown,\n brush,\n bubble,\n budget,\n bulbs,\n bullet,\n bummer,\n burger,\n burn,\n burned,\n burst,\n bus,\n busjerry,\n buy,\n caliber,\n california,\n californiaits,\n called,\n came,\n candy,\n cane,\n canine,\n cans,\n cant,\n canton,\n captured,\n car,\n careful,\n carpenter,\n carriages,\n cars,\n carsam,\n carson,\n carts,\n cat,\n cataract,\n cause,\n caused,\n causing,\n cell,\n cells,\n cents,\n certificatesone,\n change,\n changed,\n changesara,\n changing,\n channels,\n charged,\n chase,\n chasethey,\n cheap,\n cheaper,\n check,\n chef,\n childless,\n children,\n choose,\n church,\n cigarettes,\n cigars,\n cities,\n city,\n citys,\n clean,\n cleared,\n clearing,\n clicked,\n clients,\n clockwork,\n clone,\n clones,\n cloning,\n close,\n clothing,\n club,\n clubsmuch,\n coffee,\n coffers,\n coin,\n collection,\n collision,\n color,\n colors,\n come,\n comic,\n community,\n company,\n complain,\n complaints,\n completely,\n complex,\n complications,\n complied,\n concerned,\n condo,\n condominium,\n cone,\n cons,\n considerate,\n consideration,\n consisting,\n contestant,\n continued,\n conversations,\n convertible,\n correct,\n correctional,\n correctly,\n cost,\n could,\n couldnt,\n counts,\n county,\n couple,\n course,\n court,\n crazy,\n cream,\n created,\n creek,\n crew,\n crews,\n crossing,\n crosswalk,\n cub,\n cube,\n cultured,\n cup,\n currently,\n customers,\n customersthe,\n cut,\n cutting,\n cycles,\n daily,\n damage,\n day,\n days,\n daythere,\n deal,\n deals,\n death,\n debating,\n debris,\n decide,\n decided,\n decision,\n decisionfinally,\n delightful,\n delivered,\n delivers,\n demanding,\n demands,\n department,\n departments,\n desperate,\n destroyed,\n details,\n diabetes,\n diabetic,\n dictionaries,\n didnt,\n died,\n dies,\n different,\n dining,\n directions,\n director,\n dirt,\n discovered,\n disease,\n doesnt,\n dogs,\n dollars,\n dolls,\n dom,\n dominic,\n donate,\n done,\n donna,\n donorthe,\n dont,\n door,\n doors,\n doorslammer,\n downtown,\n dozen,\n dreamily,\n drinks,\n drinkspeople,\n drive,\n driver,\n drivers,\n drivethrough,\n driving,\n drizzle,\n dropped,\n drought,\n drove,\n early,\n earring,\n economy,\n eight,\n either,\n elevation,\n elsewhere,\n embrace,\n emphysema,\n employee,\n empty,\n ended,\n ending,\n english,\n enough,\n environmental,\n erupted,\n estimated,\n estrus,\n ethnic,\n even,\n evening,\n event,\n ever,\n everett,\n every,\n everyone,\n everyones,\n exact,\n except,\n exchange,\n excitedly,\n exhibitors,\n experimenting,\n explain,\n extra,\n extralarge,\n eye,\n eyesight,\n facility,\n fact,\n failure,\n families,\n fantastic,\n fault,\n featured,\n federal,\n fee,\n feel,\n feet,\n felix,\n female,\n festival,\n festivals,\n fiction,\n fight,\n fill,\n filledno,\n finally,\n find,\n fine,\n fines,\n fire,\n first,\n five,\n fiveyearold,\n fixing,\n flipped,\n following,\n food,\n foods,\n foot,\n foothill,\n forward,\n found,\n founders,\n four,\n fourdoor,\n fourslice,\n francisco,\n free,\n freeway,\n fresh,\n friction,\n friendly,\n friends,\n front,\n fruit,\n full,\n funds,\n furniture,\n future,\n gallon,\n game,\n gangster,\n gangsters,\n garbage,\n gas,\n gasoline,\n gave,\n gear,\n generating,\n get,\n gets,\n getting,\n geyser,\n gift,\n give,\n given,\n gloves,\n go,\n goal,\n goes,\n going,\n golf,\n gonethey,\n good,\n got,\n government,\n governments,\n grabbed,\n grand,\n great,\n greater,\n grocery,\n groupssave,\n groupsthe,\n grow,\n growing,\n guarantee,\n guards,\n guess,\n guessed,\n guessing,\n guides,\n gun,\n gunshots,\n guy,\n guyjerry,\n hadnt,\n half,\n halloween,\n haltturning,\n hamburgers,\n hamilton,\n handed,\n handle,\n happen,\n happened,\n happy,\n hauled,\n havent,\n hawaiian,\n hazard,\n head,\n headaches,\n heads,\n heard,\n hed,\n held,\n help,\n herman,\n high,\n higher,\n hill,\n hire,\n hit,\n hold,\n holiday,\n home,\n homebuyers,\n homeowner,\n homeowners,\n homes,\n hope,\n hopes,\n horsetrail,\n hospital,\n hot,\n hotel,\n hour,\n hourly,\n hours,\n house,\n housing,\n howard,\n however,\n huge,\n hurriedly,\n husband,\n hydrant,\n ice,\n id,\n idea,\n ideas,\n ill,\n im,\n immediately,\n implanted,\n inc,\n income,\n incomes,\n inconsiderate,\n inevitably,\n inferno,\n influence,\n injured,\n inmates,\n insurance,\n interest,\n invite,\n irritating,\n isnt,\n issued,\n item,\n items,\n ive,\n jail,\n japanesehe,\n jerry,\n jerrys,\n job,\n jobrelated,\n john,\n johnson,\n joke,\n joy,\n jumped,\n kick,\n kids,\n killing,\n kinds,\n kitten,\n kittens,\n kneejerry,\n knew,\n know,\n lake,\n landfill,\n landlord,\n lane,\n lap,\n last,\n late,\n later,\n latest,\n lawn,\n leading,\n least,\n lee,\n left,\n leftovers,\n legal,\n less,\n let,\n letting,\n libraries,\n life,\n light,\n like,\n liked,\n limp,\n line,\n lined,\n lines,\n lips,\n liquid,\n listen,\n listening,\n little,\n lived,\n lives,\n living,\n loan,\n loans,\n local,\n long,\n look,\n looking,\n lookingtim,\n los,\n lose,\n lot,\n lottery,\n loud,\n love,\n loved,\n lowest,\n lozano,\n lucky,\n luxury,\n made,\n magazine,\n magazines,\n main,\n maintenance,\n major,\n make,\n making,\n man,\n managed,\n manager,\n mans,\n many,\n market,\n married,\n massive,\n material,\n mcrapthe,\n mechanic,\n medical,\n meeting,\n messages,\n middleaged,\n might,\n mild,\n mile,\n miles,\n milk,\n milkplus,\n million,\n millions,\n mind,\n minimum,\n minor,\n minutes,\n money,\n moneya,\n moneysam,\n monica,\n month,\n months,\n morehowever,\n morning,\n mountain,\n move,\n moved,\n movie,\n movies,\n mr,\n mrs,\n much,\n murdersuicide,\n music,\n must,\n n,\n name,\n names,\n nancy,\n nationwide,\n near,\n nearby,\n necessary,\n necessarywell,\n negotiations,\n neighbor,\n neighborhood,\n neighbors,\n never,\n nevertheless,\n new,\n newest,\n newspaper,\n newsstand,\n next,\n nextdoor,\n nice,\n nicest,\n night,\n nightit,\n nine,\n nitrogen,\n nobody,\n noise,\n nonfat,\n nonflammable,\n north,\n northville,\n notify,\n number,\n numbers,\n nutritious,\n occurred,\n occurs,\n oceanside,\n octane,\n offer,\n offers,\n officer,\n officers,\n official,\n officials,\n offset,\n often,\n oil,\n ok,\n old,\n one,\n onebedroom,\n onehour,\n ones,\n onto,\n operationninety,\n opportunityeveryone,\n order,\n ordering,\n others,\n ought,\n outdoor,\n outdoors,\n outside,\n overpaid,\n overpaying,\n owner,\n owners,\n owns,\n paid,\n painmrs,\n paper,\n paperthe,\n park,\n parked,\n parking,\n part,\n party,\n pasadena,\n passing,\n pay,\n paying,\n penny,\n people,\n per,\n percent,\n perfect,\n period,\n permitted,\n personal,\n persons,\n phoenix,\n phone,\n pianist,\n piano,\n picked,\n pile,\n pine,\n pistol,\n pizza,\n place,\n planners,\n plants,\n plastic,\n plates,\n play,\n played,\n player,\n playgrounda,\n playing,\n plot,\n plowed,\n plus,\n pm,\n police,\n popular,\n portable,\n post,\n practice,\n practiced,\n president,\n pretty,\n price,\n prices,\n prince,\n prison,\n prisoners,\n private,\n probably,\n problem,\n problems,\n proceeds,\n produce,\n profit,\n property,\n proposal,\n proprietor,\n pros,\n proven,\n provide,\n pulp,\n pumping,\n puppies,\n pursuing,\n put,\n quell,\n question,\n questionandanswer,\n quieter,\n quietershe,\n quite,\n radios,\n raffle,\n raging,\n rain,\n raining,\n rainstorm,\n raises,\n ran,\n range,\n rates,\n rather,\n ration,\n rattle,\n razors,\n reading,\n reads,\n ready,\n realtor,\n reason,\n receives,\n recent,\n reconsider,\n reduce,\n reduced,\n reduction,\n refill,\n refused,\n regular,\n released,\n remaining,\n remarked,\n remove,\n removed,\n rent,\n rental,\n rentals,\n renters,\n renting,\n rents,\n repairs,\n resident,\n residents,\n respond,\n response,\n rest,\n restaurant,\n restaurants,\n restored,\n resulted,\n resumed,\n retired,\n retirees,\n return,\n revolver,\n rick,\n right,\n road,\n roadside,\n roof,\n room,\n ruined,\n run,\n sad,\n safely,\n said,\n sale,\n sam,\n samantha,\n san,\n sandwich,\n sandwiches,\n santa,\n sara,\n saturday,\n save,\n saved,\n savings,\n saw,\n saxophone,\n saxophonist,\n say,\n saying,\n says,\n scaldinghe,\n scared,\n scheduled,\n scouts,\n seashell,\n seatbelt,\n second,\n secured,\n security,\n seekers,\n seem,\n seemed,\n selected,\n sell,\n sellers,\n sent,\n set,\n seven,\n several,\n shaking,\n shapes,\n ...]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create posting lists\n",
    "inverted_index.create_posting_list()\n",
    "\n",
    "# Let's see the posting list\n",
    "inverted_index.posting_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.650151Z",
     "end_time": "2024-06-23T19:49:24.758644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.710448Z",
     "end_time": "2024-06-23T19:49:24.765489Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** ir_system documents:\n",
      " [['samantha', 'like', 'many', 'renters', 'tired', 'renting', 'one', 'reason', 'annual', 'rent', 'goes', 'like', 'clockwork', 'every', 'year', 'landlord', 'raises', 'rent', 'five', 'percent', 'another', 'reason', 'neighbors', 'new', 'neighbors', 'always', 'seem', 'inconsiderate', 'ones', 'moved', 'said', 'first', 'neighbor', 'doorslammer', 'always', 'knew', 'came', 'home', 'left', 'home', 'moved', 'saxophonist', 'moved', 'saxophonist', 'practiced', 'two', 'hours', 'day', 'saturday', 'friends', 'would', 'come', 'id', 'get', 'listen', 'whole', 'band', 'called', 'police', 'said', 'saxophone', 'playing', 'permitted', 'apartments', 'four', 'hours', 'day', 'saxophone', 'playing', 'jobrelated', 'told', 'lucky', 'guy', 'playing', 'two', 'hours', 'daythere', 'many', 'unhappy', 'renters', 'also', 'happy', 'renters', 'ive', 'lucky', 'whole', 'life', 'said', 'howard', 'middleaged', 'man', 'neighbors', 'couldnt', 'better', 'picked', 'one', 'neighbor', 'chef', 'hed', 'bring', 'best', 'leftovers', 'world', 'another', 'neighbor', 'pianist', 'played', 'delightful', 'music', 'another', 'neighbor', 'mechanic', 'tuneups', 'changed', 'oil', 'car', 'latest', 'neighbor', 'birder', 'go', 'birding', 'every', 'weekend', 'binocularsdifferent', 'persons', 'different', 'attitudes', 'samantha', 'saw', 'saxophone', 'player', 'irritating', 'yet', 'howard', 'saw', 'piano', 'player', 'delightful', 'millions', 'people', 'would', 'happy', 'roof', 'head', 'yet', 'millions', 'would', 'complain', 'roof', 'wrong', 'color'], ['people', 'joke', 'one', 'los', 'angeles', 'reads', 'everyone', 'watches', 'tv', 'rents', 'videos', 'goes', 'movies', 'popular', 'reading', 'material', 'comic', 'books', 'movie', 'magazines', 'tv', 'guides', 'city', 'libraries', '10', 'percent', 'traffic', 'car', 'washes', 'explain', 'annual', 'book', 'festival', 'west', 'los', 'angeles', 'sold', 'year', 'year', 'people', 'wait', 'half', 'hour', 'parking', 'space', 'become', 'availablethis', 'outdoor', 'festival', 'sponsored', 'newspaper', 'occurs', 'every', 'april', 'one', 'weekend', 'years', 'attendance', 'estimated', '70000', 'saturday', '75000', 'sunday', 'festival', 'featured', '280', 'exhibitors', '90', 'talks', 'given', 'authors', 'audience', 'questionandanswer', 'period', 'following', 'talk', 'autograph', 'seekers', 'sought', '150', 'authors', 'food', 'court', 'sold', 'kinds', 'popular', 'ethnic', 'foods', 'american', 'hamburgers', 'hawaiian', 'shave', 'ice', 'drinks', 'except', '7', 'parking', 'fee', 'festival', 'free', 'even', 'people', 'avoided', 'food', 'court', 'prices', 'sneaking', 'sandwiches', 'drinkspeople', 'came', 'california', 'one', 'couple', 'drove', 'san', 'francisco', 'sixth', 'year', 'love', 'said', 'husband', 'fantastic', 'great', 'outdoors', 'among', 'many', 'books', 'authors', 'get', 'good', 'deals', 'toothe', 'idea', 'festival', 'occurred', 'years', 'ago', 'nobody', 'knew', 'would', 'succeed', 'although', 'book', 'festivals', 'already', 'popular', 'us', 'cities', 'would', 'los', 'angeles', 'residents', 'embrace', 'one', 'angelenos', 'unpredictable', 'said', 'one', 'festival', 'founders'], ['man', 'woman', 'died', 'apparent', 'murdersuicide', 'last', 'night', 'altadena', 'man', '74yearold', 'dominic', 'vittorio', 'woman', '70yearold', 'wife', 'victoria', 'couple', 'married', '50', 'years', 'fact', '50th', 'anniversary', 'occurred', 'month', 'ago', 'according', 'nextdoor', 'neighbor', 'mrs', 'allen', 'couple', 'childless', 'close', 'friends', 'mr', 'vittorio', 'retired', 'carpenter', 'emphysema', 'blind', 'one', 'eye', 'cataract', 'wife', 'diabetic', 'already', 'one', 'foot', 'amputated', 'complications', 'disease', 'eyesight', 'almost', 'completely', 'gonethey', 'nice', 'couple', 'said', 'mrs', 'allen', 'ive', 'lived', 'next', 'last', '20', 'years', 'im', 'widowed', 'dom', 'always', 'used', 'help', 'things', 'like', 'changing', 'light', 'bulbs', 'fixing', 'appliances', 'kids', 'always', 'friendly', 'neighborhood', 'kids', 'every', 'halloween', 'handed', 'tons', 'candy', 'fresh', 'fruit', 'eight', 'years', 'ago', 'vicky', 'came', 'diabetes', 'things', 'havent', 'dom', 'used', 'friendly', 'full', 'life', 'seemed', 'get', 'quieter', 'quietershe', 'used', 'come', 'place', 'twice', 'week', 'would', 'talk', 'kinds', 'things', 'nicest', 'time', 'happened', 'less', 'less', 'got', 'sicker', 'would', 'go', 'house', 'week', 'would', 'talk', 'conversations', 'steadily', 'got', 'shorter', 'seemed', 'lose', 'interest', 'listening', 'talking', 'didnt', 'say', 'could', 'tell', 'lot', 'painmrs', 'allen', 'said', 'hadnt', 'even', 'talked', 'either', 'vittorios', 'almost', 'year', 'never', 'came', 'even', 'food', 'delivered', 'local', 'agency', 'said', 'heard', 'two', 'gunshots', 'last', 'nightit', 'scared', 'half', 'death', 'immediately', 'called', 'police', 'sad', 'ending', 'nice', 'people', 'said', 'together', 'sickness', 'alone', 'world'], ['jerry', 'baldwin', '30', 'years', 'old', 'manager', 'pizza', 'restaurant', 'lived', 'apartment', 'one', 'mile', 'north', 'restaurant', 'walked', 'work', 'raining', 'took', 'busjerry', 'loved', 'gangster', 'movies', 'new', 'one', 'came', 'would', 'go', 'theater', 'watch', 'new', 'movie', 'three', 'four', 'times', 'went', 'video', 'jerry', 'would', 'buy', 'video', 'barneys', 'video', 'store', 'jerry', 'home', 'collection', '1000', 'gangster', 'videos', 'old', 'ones', 'new', 'ones', 'color', 'black', 'white', 'english', 'spanish', 'japanesehe', 'loved', 'could', 'tell', 'name', 'movie', 'director', 'stars', 'plot', 'say', 'liked', 'pulp', 'fiction', 'well', 'jerry', 'would', 'rattle', 'details', 'movie', 'would', 'invite', 'place', 'watch', 'time', 'nice', 'guyjerry', 'finally', 'decided', 'would', 'like', 'gun', 'like', 'gangsters', 'saved', 'money', 'couple', 'years', 'went', 'gun', 'store', 'bought', 'used', '38', 'caliber', 'revolver', '300', 'also', 'bought', 'couple', 'boxes', 'ammunition', 'following', 'saturday', 'morning', 'went', 'gun', 'club', 'practice', 'new', 'revolver', 'club', '10', 'minutes', 'accidentally', 'dropped', 'pistol', 'gun', 'went', 'bullet', 'went', 'jerrys', 'right', 'kneejerry', 'walks', 'limp', 'cane', 'like', 'gangsters'], ['sam', 'unemployed', 'piano', 'tuner', 'said', 'second', 'thing', 'ever', 'life', 'first', 'thing', 'afghan', 'blanket', 'church', 'raffle', '25', 'years', 'old', 'much', 'bigger', '120000', 'big', 'cube', 'state', 'lottery', 'game', 'win', 'contestant', 'must', 'first', 'guess', 'number', 'spinning', 'cube', 'stop', 'cube', 'six', 'numbers', '1x', '10x', '50x', '100x', '500x', '1000x', 'correct', 'contestant', 'must', 'guess', 'two', 'selected', 'variables', 'going', 'greater', 'guessing', 'number', 'appears', 'cube', 'guarantee', 'win', 'moneysam', 'correctly', 'guessed', '1000x', 'still', 'choose', 'two', 'variables', 'one', 'variable', 'number', 'cars', 'would', 'run', 'stop', 'sign', 'hill', 'street', 'lake', 'avenue', 'six', 'hours', 'variable', 'number', 'times', 'teenage', 'boy', 'would', 'change', 'tv', 'channels', 'threehour', 'period', 'tough', 'decisionfinally', 'sam', 'flipped', 'coin', 'came', 'heads', 'sam', 'picked', 'teenager', 'picked', 'right', 'stop', 'sign', 'run', '76', 'times', 'teen', 'clicked', '120', 'times', 'sixtyyearold', 'sam', 'jumped', 'joy', '1000', 'times', '120', '120000', 'sam', 'dreamily', 'left', 'lottery', 'studio', 'talking', 'excitedly', 'cell', 'phone', 'crossing', 'street', 'got', 'hit', 'little', 'sports', 'carsam', 'slowly', 'getting', 'better', 'hospital', 'month', 'hospital', 'bill', '110000', 'insurance', 'company', 'little', 'sports', 'cars', 'owner', 'sued', 'sam', '9000', 'worth', 'repairs', 'also', 'sam', 'still', 'pay', 'federal', 'taxes', 'winnings', 'sam', 'doesnt', 'play', 'state', 'lottery', 'says', 'better', 'unlucky'], ['work', 'crew', 'consisting', '150', 'volunteers', 'worked', 'eight', 'hours', 'light', 'drizzle', 'saturday', 'clean', 'carson', 'creek', 'almost', 'nine', 'tons', 'debris', 'job', 'well', 'done', 'smiled', 'alan', 'specter', 'director', 'event', 'scheduled', 'come', 'back', 'one', 'time', 'three', 'years', 'course', 'hope', 'wont', 'nine', 'tons', 'garbage', 'next', 'timethe', 'garbage', 'came', 'shapes', 'sizes', 'colors', 'cans', 'bottles', 'bicycles', 'car', 'tires', 'auto', 'batteries', 'sofas', 'furniture', 'clothing', 'shopping', 'carts', 'bowling', 'balls', 'plastic', 'bags', 'dolls', 'baby', 'carriages', 'tv', 'antennas', 'portable', 'radios', 'even', 'golf', 'bag', 'full', 'set', 'golf', 'clubsmuch', 'backbreaking', 'work', 'done', 'two', 'community', 'groupsthe', 'cub', 'scouts', 'boy', 'scouts', 'two', 'environmental', 'groupssave', 'bay', 'watch', 'whales', 'concerned', 'retirees', 'volunteers', 'police', 'fire', 'departments', 'assisted', 'everyone', 'issued', 'boots', 'gloves', 'rain', 'gear', 'work', 'occurred', 'along', 'twomile', 'stretch', 'streambed', 'debris', 'hauled', 'roadside', 'trucks', 'lined', 'take', 'trash', 'landfill', '500', 'big', 'yellow', 'trash', 'bags', 'filledno', 'one', 'found', 'anything', 'great', 'value', 'although', 'fiveyearold', 'boy', 'found', 'earring', 'thought', 'might', 'worth', 'million', 'dollars', 'shiny', 'said', 'would', 'sell', 'would', 'donate', 'half', 'proceeds', 'watch', 'whales', 'use', 'half', 'buy', 'triplescoop', 'ice', 'cream', 'cone', 'every', 'day', 'rest', 'life'], ['inmates', 'released', 'two', 'correctional', 'officers', 'held', 'week', 'tower', 'state', 'prison', 'complex', 'inmates', 'captured', 'officers', 'week', 'ago', 'two', 'officers', 'tried', 'quell', 'food', 'fight', 'main', 'dining', 'room', 'food', 'fight', 'erupted', 'prisoners', 'discovered', 'candy', 'ration', 'cut', 'half', 'candy', 'popular', 'bartering', 'item', 'inmates', 'trade', 'cigarettes', 'cigars', 'magazines', 'stationery', 'legal', 'dictionaries', 'items', 'prison', 'officials', 'said', 'necessary', 'cut', 'back', 'luxury', 'item', 'order', 'provide', 'basic', 'items', 'like', 'soap', 'razors', 'toilet', 'paperthe', 'prisoners', 'went', 'berserk', 'reduction', 'threw', 'food', 'plates', 'silverware', 'doors', 'windows', 'guards', 'grabbed', 'two', 'guards', 'hauled', 'tower', 'tower', 'door', 'secured', 'sent', 'messages', 'prison', 'officials', 'demanding', 'big', 'bags', 'candy', 'exchange', 'sparing', 'guards', 'lives', 'warden', 'complied', 'demands', 'week', 'negotiations', 'prisoners', 'approved', 'deal', 'restored', 'candy', 'ration', 'return', 'administration', 'said', 'would', 'reduce', 'daily', 'soap', 'allotments', '75', 'percent'], ['homebuyers', 'nationwide', 'watching', 'housing', 'prices', 'go', 'high', 'go', 'question', 'everyones', 'lips', 'long', 'interest', 'rates', 'stay', 'around', '5', 'percent', 'theres', 'telling', 'remarked', 'one', 'realtor', 'santa', 'monica', 'californiaits', 'crazy', 'said', 'tim', 'looking', 'house', 'near', 'beach', '1993', 'bought', 'first', 'place', 'twobedroom', 'condominium', 'venice', '70000', 'friends', 'thought', 'overpaying', 'five', 'years', 'later', 'move', 'sold', '230000', 'nice', 'profit', 'last', 'year', 'visiting', 'friends', 'saw', 'local', 'paper', 'exact', 'condo', 'sale', '510000it', 'sellers', 'market', 'homebuyers', 'feel', 'like', 'offer', 'least', '10', 'percent', 'asking', 'price', 'donna', 'new', 'owner', 'onebedroom', 'condo', 'venice', 'beach', 'said', 'thats', 'told', 'owner', 'whatever', 'anyone', 'offers', 'ill', 'give', '20000', 'table', 'dont', 'pay', 'realtor', 'tired', 'lookingtim', 'says', 'hopes', 'doesnt', 'get', 'desperate', 'whether', 'decide', 'buy', 'decide', 'buy', 'still', 'feel', 'like', 'made', 'wrong', 'decision', 'buy', 'feel', 'like', 'overpaid', 'dont', 'buy', 'want', 'kick', 'passing', 'great', 'opportunityeveryone', 'says', 'bubble', 'burst', 'sometime', 'everyone', 'hopes', 'burst', 'day', 'sell', 'house', 'even', 'government', 'officials', 'idea', 'future', 'bring', 'say', 'inevitably', 'things', 'go', 'cycles', 'said', 'state', 'director', 'housing', 'goes', 'must', 'come', 'know', 'housing', 'prices', 'always', 'stay', 'little', 'higher', 'go', 'cant', 'lose', 'long', 'run', 'twenty', 'years', 'road', 'house', 'always', 'worth', 'paid'], ['mountain', 'town', 'canton', 'elevation', '6000', 'feet', 'surrounded', 'thick', 'underbrush', 'pine', 'trees', 'six', 'years', 'drought', 'plants', 'major', 'fire', 'hazard', 'thousands', 'trees', 'tons', 'underbrush', 'going', 'removed', 'next', 'five', 'years', 'minimum', 'cost', '3', 'million', 'brush', 'removed', 'first', 'trees', 'toppled', 'removed', 'cleared', 'nonflammable', 'area', 'safely', 'surround', 'town', '4000residents', 'look', 'forward', 'work', 'help', 'town', 'survive', 'future', 'inferno', 'two', 'problems', 'said', 'one', 'resident', 'extra', 'trucks', 'going', 'make', 'traffic', 'pretty', 'bad', 'area', 'cleared', 'make', 'sure', 'dirt', 'bikers', 'dont', 'try', 'make', 'cleared', 'area', 'personal', 'playgrounda', 'recent', 'fire', 'burned', '4000', 'acres', 'destroyed', '11', 'homes', 'nearby', 'hamilton', 'fire', 'raging', 'toward', 'canton', 'sudden', 'rainstorm', 'put', 'residents', 'know', 'wont', 'get', 'lucky', 'twice', 'looking', 'forward', 'massive', 'clearing', 'operationninety', 'percent', 'cutting', 'clearing', 'paid', 'federal', 'funds', 'unfortunately', 'trees', 'private', 'property', 'must', 'paid', 'residents', 'prices', 'range', 'high', '1000', 'cut', 'remove', 'one', 'tree', 'officials', 'say', 'residents', 'apply', 'state', 'federal', 'loans', 'necessarywell', 'good', 'asked', 'thelma', '65yearold', 'widow', 'im', 'living', 'social', 'security', 'ive', 'got', 'four', 'trees', 'property', 'governments', 'going', 'loan', 'money', 'know', 'theres', 'way', 'pay', 'back', 'supposed', 'planners', 'big', 'ideas', 'ought', 'think', 'little', 'people'], ['79yearold', 'man', 'slightly', 'injured', 'saturday', 'waiting', 'brand', 'new', 'convertible', 'drivethrough', 'lane', 'burger', 'prince', 'restaurant', 'herman', 'sherman', 'northville', 'suffered', 'mild', 'burn', '900', 'pm', 'young', 'female', 'employee', 'accidentally', 'spilled', 'cup', 'coffee', 'lap', 'sherman', 'said', 'coffee', 'hot', 'scaldinghe', 'refused', 'medical', 'aid', 'saying', 'problem', 'stain', 'slacks', 'would', 'wash', 'given', 'fresh', 'refill', 'sherman', 'drove', 'restaurant', 'manager', 'john', 'johnson', 'gave', 'two', 'free', 'gift', 'certificatesone', 'extralarge', 'coffee', 'one', 'restaurants', 'newest', 'sandwich', 'mcrapthe', 'employee', 'new', 'hire', 'let', 'go', 'later', 'evening', 'quite', 'upset', 'said', 'would', 'probably', 'sue', 'burger', 'prince', 'letting', 'go', 'said', 'mans', 'fault', 'ordering', 'something', 'might', 'able', 'spill'], ['24yearold', 'los', 'angeles', 'man', 'taken', 'hospital', 'county', 'jail', 'leading', 'police', 'onehour', 'freeway', 'chase', 'stolen', 'suv', 'chase', 'ended', 'downtown', 'los', 'angeles', 'front', 'spring', 'hotel', 'chase', 'uneventful', 'except', 'empty', 'bottle', 'whiskey', 'driver', 'threw', 'one', 'police', 'vehiclewhen', 'driver', 'got', 'downtown', 'things', 'started', 'happen', 'ran', 'fire', 'hydrant', 'water', 'spewed', 'hydrant', 'causing', 'geyser', 'ruined', 'books', 'several', 'carts', 'vendor', 'put', 'outside', 'attract', 'customers', 'bookstore', 'driver', 'hurriedly', 'turned', 'west', 'onto', 'grand', 'avenue', 'managed', 'bang', 'three', 'parked', 'cars', 'one', 'side', 'street', 'two', 'cars', 'side', 'driver', 'also', 'tried', 'run', 'police', 'officer', 'standing', 'crosswalk', 'ordering', 'haltturning', 'north', 'driver', 'caused', 'bus', 'slam', 'brakes', 'avoid', 'collision', 'bus', 'empty', 'bus', 'driver', 'uninjured', 'however', 'two', 'police', 'cars', 'pursuing', 'suv', 'different', 'directions', 'lucky', 'one', 'ran', 'front', 'bus', 'back', 'drivers', 'braked', 'early', 'enough', 'damage', 'cars', 'minor', 'officers', 'resumed', 'chasethey', 'went', 'two', 'blocks', 'north', 'find', 'suv', 'come', 'full', 'stop', 'plowed', 'newspaper', 'stand', 'driver', 'wearing', 'seatbelt', 'slumped', 'behind', 'steering', 'wheel', 'proprietor', 'newsstand', 'yelling', 'driver', 'shaking', 'magazine', 'police', 'called', 'ambulance', 'charged', 'driver', 'failure', 'yield', 'police', 'officer', 'driving', 'influence'], ['company', 'phoenix', 'arizona', 'says', 'clone', 'cat', 'actually', 'said', 'felix', 'lee', 'president', 'twice', 'nice', 'inc', 'dont', 'even', 'wait', 'beloved', 'cat', 'dies', 'already', 'clients', 'whose', 'clone', 'lives', 'donorthe', 'price', 'steep', 'clone', 'cat', 'cost', '50000', 'first', 'veterinarian', 'must', 'biopsy', 'cat', 'sent', 'twin', 'inc', 'cultured', 'grow', 'fresh', 'new', 'cells', 'new', 'cells', 'stored', 'liquid', 'nitrogen', 'notify', 'twin', 'inc', 'ready', 'clone', 'time', 'pay', 'half', 'amount', '25000', 'cultured', 'cell', 'implanted', 'female', 'cat', 'estrus', 'goes', 'well', 'kitten', 'born', '60', 'days', 'later', 'new', 'kitten', 'weaned', 'eight', 'weeks', 'twin', 'inc', 'delivers', 'kitten', 'receives', 'remaining', '25000we', 'growing', 'company', 'said', 'lee', 'facility', 'handle', 'dozen', 'births', 'year', 'goal', 'produce', '50', 'kittens', '50', 'puppies', 'year', 'company', 'currently', 'experimenting', 'stray', 'dogs', 'canine', 'clones', 'seem', 'perfect', 'bizarre', 'nevertheless', 'lee', 'believes', 'successfully', 'cloning', 'dogs', 'year'], ['sara', 'smith', 'pasadena', 'resident', 'went', 'shopping', '30', 'lived', '3037', 'n', 'foothill', 'street', 'since', '1992', 'sara', 'married', 'john', 'seven', 'years', 'two', 'children', 'bob', 'five', 'years', 'old', 'nancy', 'three', 'sara', 'owns', '1995', 'fourdoor', 'blue', 'toyola', '9', 'sara', 'got', 'car', 'drove', 'barget', 'department', 'store', 'mile', 'awaybarget', 'holiday', 'sale', 'sara', 'bought', 'fourslice', 'toaster', '2995', 'plus', 'tax', 'regular', 'price', '3995', 'paid', 'check', 'way', 'home', 'sara', 'stopped', 'milkplus', 'buy', 'gallon', 'nonfat', 'milk', 'milk', '350', 'sara', 'got', '50', 'cents', 'back', 'changesara', 'arrived', 'home', '10', 'john', 'kids', 'still', 'sleeping', 'woke', 'made', 'hot', 'nutritious', 'breakfast', 'everyone'], ['residents', 'southern', 'california', 'trying', 'get', 'used', 'skyrocketing', 'prices', 'gasoline', 'average', 'price', '87', 'octane', 'economy', 'gas', '222', 'almost', '30', 'percent', 'higher', 'today', '12', 'months', 'ago', 'lowest', 'gas', 'price', 'southland', 'right', '209', 'gallon', 'seashell', 'station', 'arcadia', 'station', 'manager', 'everett', 'said', 'reason', 'gas', 'cheaper', 'elsewhere', 'bought', 'lot', 'gas', 'two', 'years', 'ago', 'reduced', 'prices', 'passing', 'savings', 'customersthe', 'lines', 'seashell', 'station', 'often', 'run', '10', '20', 'vehicles', 'long', 'police', 'several', 'times', 'cars', 'block', 'traffic', 'horsetrail', 'drive', 'everett', 'said', 'tell', 'people', 'line', 'barco', 'station', 'block', 'away', '214', 'theyd', 'rather', 'wait', 'save', '5', 'cents', 'ok', 'course', 'dont', 'mind', 'making', 'moneya', 'young', 'man', 'pumping', 'gas', 'said', 'waited', 'line', '20', 'minutes', 'asked', 'didnt', 'go', 'block', 'away', 'lines', 'said', 'every', 'penny', 'counts', 'bought', '99', 'bummer', 'gas', '1', 'gallon', 'pretty', 'cheap', 'even', 'though', 'get', 'eight', 'miles', 'per', 'gallon', 'wasnt', 'paying', 'much', 'fill', 'tank', 'todays', 'prices', 'killing', 'drive', 'work', 'drive', 'grocery', 'store', 'thats', 'used', 'drive', 'around', 'neighborhood', 'show', 'wheels', 'cant'], ['oceanside', 'community', 'lozano', 'beach', 'debating', 'whether', 'allow', 'homeowners', 'rent', 'homes', 'weekly', 'basis', 'summer', 'rentals', 'produce', 'high', 'incomes', 'owners', 'city', 'gets', 'part', 'income', '15percent', 'surcharge', 'owner', 'boon', 'coffers', 'said', 'rick', 'brown', 'city', 'manager', 'summer', 'homeowners', 'bring', '2000', 'week', 'morehowever', 'rentals', 'also', 'worms', 'city', 'stopped', 'allowing', 'weekly', 'rentals', '10', 'years', 'ago', 'problems', 'generating', 'two', 'three', 'even', 'four', 'families', 'would', 'pile', 'two', 'threebedroom', 'house', 'would', 'park', 'cars', 'lawn', 'produce', 'huge', 'amounts', 'trash', 'sometimes', 'would', 'toss', 'trash', 'streets', 'sidewalksnoise', 'would', 'another', 'problem', 'people', 'would', 'party', 'late', 'loud', 'every', 'night', 'abuse', 'created', 'lot', 'friction', 'neighbors', 'resulted', 'extra', 'work', 'city', 'maintenance', 'crews', 'police', 'respond', 'almost', 'hourly', 'residents', 'complaints', 'noise', 'music', 'trash', 'parking', 'problems', 'citys', 'budget', 'problems', 'making', 'reconsider', 'bancity', 'officials', 'hold', 'community', 'meeting', 'next', 'week', 'listen', 'pros', 'cons', 'one', 'official', 'already', 'suggested', 'proposal', 'thinks', 'fine', 'might', 'work', 'city', 'respond', 'complaints', 'homeowner', 'charged', '200', 'per', 'response', 'fine', 'might', 'cause', 'homeowner', 'careful', 'rent', 'people', 'sure', 'considerate', 'neighbors', 'city', 'would', 'still', 'get', '15', 'percent', 'rental', 'fee', 'even', 'homeowners', 'rent', 'totally', 'offset', 'fines', 'city', 'would', 'post', 'inconsiderate', 'renters', 'names', 'city', 'website', 'homeowners', 'would', 'know', 'themsome', 'officials', 'think', 'ban', 'continued', 'visitors', 'community', 'already', 'proven', 'consideration', 'others', 'money', 'isnt', 'worth', 'headaches', 'cause']]\n"
     ]
    }
   ],
   "source": [
    "print('**** ir_system documents:\\n', inverted_index.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.713510Z",
     "end_time": "2024-06-23T19:49:24.766639Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** ir_system documents:\n",
      " [1, 10, 1000, 1000x, 100x, 10x, 11, 110000, 12, 120, 120000, 15, 150, 15percent, 1992, 1993, 1995, 1x, 20, 200, 2000, 20000, 209, 214, 222, 230000, 24yearold, 25, 25000, 25000we, 280, 2995, 3, 30, 300, 3037, 350, 38, 3995, 4000, 4000residents, 5, 50, 500, 50000, 500x, 50th, 50x, 510000it, 60, 6000, 65yearold, 7, 70000, 70yearold, 74yearold, 75, 75000, 76, 79yearold, 87, 9, 90, 900, 9000, 99, able, abuse, accidentally, according, acres, actually, administration, afghan, agency, ago, aid, alan, allen, allotments, allow, allowing, almost, alone, along, already, also, altadena, although, always, ambulance, american, ammunition, among, amount, amounts, amputated, angelenos, angeles, anniversary, annual, another, antennas, anyone, anything, apartment, apartments, apparent, appears, appliances, apply, approved, april, arcadia, area, arizona, around, arrived, asked, asking, assisted, attendance, attitudes, attract, audience, authors, auto, autograph, availablethis, avenue, average, avoid, avoided, away, awaybarget, baby, back, backbreaking, bad, bag, bags, baldwin, balls, ban, bancity, band, bang, barco, barget, barneys, bartering, basic, basis, batteries, bay, beach, become, behind, believes, beloved, berserk, best, better, bicycles, big, bigger, bikers, bill, binocularsdifferent, biopsy, birder, birding, births, bizarre, black, blanket, blind, block, blocks, blue, bob, book, books, bookstore, boon, boots, born, bottle, bottles, bought, bowling, boxes, boy, braked, brakes, brand, breakfast, bring, brown, brush, bubble, budget, bulbs, bullet, bummer, burger, burn, burned, burst, bus, busjerry, buy, caliber, california, californiaits, called, came, candy, cane, canine, cans, cant, canton, captured, car, careful, carpenter, carriages, cars, carsam, carson, carts, cat, cataract, cause, caused, causing, cell, cells, cents, certificatesone, change, changed, changesara, changing, channels, charged, chase, chasethey, cheap, cheaper, check, chef, childless, children, choose, church, cigarettes, cigars, cities, city, citys, clean, cleared, clearing, clicked, clients, clockwork, clone, clones, cloning, close, clothing, club, clubsmuch, coffee, coffers, coin, collection, collision, color, colors, come, comic, community, company, complain, complaints, completely, complex, complications, complied, concerned, condo, condominium, cone, cons, considerate, consideration, consisting, contestant, continued, conversations, convertible, correct, correctional, correctly, cost, could, couldnt, counts, county, couple, course, court, crazy, cream, created, creek, crew, crews, crossing, crosswalk, cub, cube, cultured, cup, currently, customers, customersthe, cut, cutting, cycles, daily, damage, day, days, daythere, deal, deals, death, debating, debris, decide, decided, decision, decisionfinally, delightful, delivered, delivers, demanding, demands, department, departments, desperate, destroyed, details, diabetes, diabetic, dictionaries, didnt, died, dies, different, dining, directions, director, dirt, discovered, disease, doesnt, dogs, dollars, dolls, dom, dominic, donate, done, donna, donorthe, dont, door, doors, doorslammer, downtown, dozen, dreamily, drinks, drinkspeople, drive, driver, drivers, drivethrough, driving, drizzle, dropped, drought, drove, early, earring, economy, eight, either, elevation, elsewhere, embrace, emphysema, employee, empty, ended, ending, english, enough, environmental, erupted, estimated, estrus, ethnic, even, evening, event, ever, everett, every, everyone, everyones, exact, except, exchange, excitedly, exhibitors, experimenting, explain, extra, extralarge, eye, eyesight, facility, fact, failure, families, fantastic, fault, featured, federal, fee, feel, feet, felix, female, festival, festivals, fiction, fight, fill, filledno, finally, find, fine, fines, fire, first, five, fiveyearold, fixing, flipped, following, food, foods, foot, foothill, forward, found, founders, four, fourdoor, fourslice, francisco, free, freeway, fresh, friction, friendly, friends, front, fruit, full, funds, furniture, future, gallon, game, gangster, gangsters, garbage, gas, gasoline, gave, gear, generating, get, gets, getting, geyser, gift, give, given, gloves, go, goal, goes, going, golf, gonethey, good, got, government, governments, grabbed, grand, great, greater, grocery, groupssave, groupsthe, grow, growing, guarantee, guards, guess, guessed, guessing, guides, gun, gunshots, guy, guyjerry, hadnt, half, halloween, haltturning, hamburgers, hamilton, handed, handle, happen, happened, happy, hauled, havent, hawaiian, hazard, head, headaches, heads, heard, hed, held, help, herman, high, higher, hill, hire, hit, hold, holiday, home, homebuyers, homeowner, homeowners, homes, hope, hopes, horsetrail, hospital, hot, hotel, hour, hourly, hours, house, housing, howard, however, huge, hurriedly, husband, hydrant, ice, id, idea, ideas, ill, im, immediately, implanted, inc, income, incomes, inconsiderate, inevitably, inferno, influence, injured, inmates, insurance, interest, invite, irritating, isnt, issued, item, items, ive, jail, japanesehe, jerry, jerrys, job, jobrelated, john, johnson, joke, joy, jumped, kick, kids, killing, kinds, kitten, kittens, kneejerry, knew, know, lake, landfill, landlord, lane, lap, last, late, later, latest, lawn, leading, least, lee, left, leftovers, legal, less, let, letting, libraries, life, light, like, liked, limp, line, lined, lines, lips, liquid, listen, listening, little, lived, lives, living, loan, loans, local, long, look, looking, lookingtim, los, lose, lot, lottery, loud, love, loved, lowest, lozano, lucky, luxury, made, magazine, magazines, main, maintenance, major, make, making, man, managed, manager, mans, many, market, married, massive, material, mcrapthe, mechanic, medical, meeting, messages, middleaged, might, mild, mile, miles, milk, milkplus, million, millions, mind, minimum, minor, minutes, money, moneya, moneysam, monica, month, months, morehowever, morning, mountain, move, moved, movie, movies, mr, mrs, much, murdersuicide, music, must, n, name, names, nancy, nationwide, near, nearby, necessary, necessarywell, negotiations, neighbor, neighborhood, neighbors, never, nevertheless, new, newest, newspaper, newsstand, next, nextdoor, nice, nicest, night, nightit, nine, nitrogen, nobody, noise, nonfat, nonflammable, north, northville, notify, number, numbers, nutritious, occurred, occurs, oceanside, octane, offer, offers, officer, officers, official, officials, offset, often, oil, ok, old, one, onebedroom, onehour, ones, onto, operationninety, opportunityeveryone, order, ordering, others, ought, outdoor, outdoors, outside, overpaid, overpaying, owner, owners, owns, paid, painmrs, paper, paperthe, park, parked, parking, part, party, pasadena, passing, pay, paying, penny, people, per, percent, perfect, period, permitted, personal, persons, phoenix, phone, pianist, piano, picked, pile, pine, pistol, pizza, place, planners, plants, plastic, plates, play, played, player, playgrounda, playing, plot, plowed, plus, pm, police, popular, portable, post, practice, practiced, president, pretty, price, prices, prince, prison, prisoners, private, probably, problem, problems, proceeds, produce, profit, property, proposal, proprietor, pros, proven, provide, pulp, pumping, puppies, pursuing, put, quell, question, questionandanswer, quieter, quietershe, quite, radios, raffle, raging, rain, raining, rainstorm, raises, ran, range, rates, rather, ration, rattle, razors, reading, reads, ready, realtor, reason, receives, recent, reconsider, reduce, reduced, reduction, refill, refused, regular, released, remaining, remarked, remove, removed, rent, rental, rentals, renters, renting, rents, repairs, resident, residents, respond, response, rest, restaurant, restaurants, restored, resulted, resumed, retired, retirees, return, revolver, rick, right, road, roadside, roof, room, ruined, run, sad, safely, said, sale, sam, samantha, san, sandwich, sandwiches, santa, sara, saturday, save, saved, savings, saw, saxophone, saxophonist, say, saying, says, scaldinghe, scared, scheduled, scouts, seashell, seatbelt, second, secured, security, seekers, seem, seemed, selected, sell, sellers, sent, set, seven, several, shaking, shapes, shave, sherman, shiny, shopping, shorter, show, sicker, sickness, side, sidewalksnoise, sign, silverware, since, six, sixth, sixtyyearold, sizes, skyrocketing, slacks, slam, sleeping, slightly, slowly, slumped, smiled, smith, sneaking, soap, social, sofas, sold, something, sometime, sometimes, sought, southern, southland, space, spanish, sparing, specter, spewed, spill, spilled, spinning, sponsored, sports, spring, stain, stand, standing, stars, started, state, station, stationery, stay, steadily, steep, steering, still, stolen, stop, stopped, store, stored, stray, streambed, street, streets, stretch, studio, succeed, successfully, sudden, sue, sued, suffered, suggested, summer, sunday, supposed, surcharge, sure, surround, surrounded, survive, suv, table, take, taken, talk, talked, talking, talks, tank, tax, taxes, teen, teenage, teenager, tell, telling, thats, theater, thelma, themsome, theres, theyd, thick, thing, things, think, thinks, though, thought, thousands, three, threebedroom, threehour, threw, tim, time, times, timethe, tired, tires, toaster, today, todays, together, toilet, told, tons, took, toothe, toppled, toss, totally, tough, toward, tower, town, toyola, trade, traffic, trash, tree, trees, tried, triplescoop, trucks, try, trying, tuner, tuneups, turned, tv, twenty, twice, twin, two, twobedroom, twomile, underbrush, unemployed, uneventful, unfortunately, unhappy, uninjured, unlucky, unpredictable, upset, us, use, used, value, variable, variables, vehicles, vehiclewhen, vendor, venice, veterinarian, vicky, victoria, video, videos, visiting, visitors, vittorio, vittorios, volunteers, wait, waited, waiting, walked, walks, want, warden, wash, washes, wasnt, watch, watches, watching, water, way, weaned, wearing, website, week, weekend, weekly, weeks, well, went, west, whales, whatever, wheel, wheels, whether, whiskey, white, whole, whose, widow, widowed, wife, win, windows, winnings, woke, woman, wont, work, worked, world, worms, worth, would, wrong, year, years, yelling, yellow, yet, yield, young]\n"
     ]
    }
   ],
   "source": [
    "print('**** ir_system documents:\\n', inverted_index.posting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.755444Z",
     "end_time": "2024-06-23T19:49:24.832842Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12, 5}\n",
      "{8, 10, 5}\n",
      "{6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "{7}\n",
      "{0, 2, 7, 12, 14}\n"
     ]
    }
   ],
   "source": [
    "ir_system = QueryProcessor(inverted_index)\n",
    "ir_system.create_prefix_trie()\n",
    "# Now we test our sample\n",
    "print(ir_system.search('buy and car'))\n",
    "print(ir_system.search('fire or water'))\n",
    "print(ir_system.search('not example'))\n",
    "print(ir_system.search('s*a and house'))\n",
    "print(ir_system.search('s*a or house'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-23T19:49:24.818144Z",
     "end_time": "2024-06-23T19:49:24.833110Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
